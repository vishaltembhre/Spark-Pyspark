{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Glue - data catalog (metadata) & ETL engine (inbuilt spark) [fully managed]\n",
    "-Data Catalog-\n",
    "--database[logical store not physical(physically its present in RDS/S3/Redshift)]\n",
    "--to query that data (Glue Table) present in S3 using glue metadata we can use Athena\n",
    "--using Glue-crawler we can read all the object from S3 to create glue table\n",
    "--without crawler we can create table & provide table schema (column names and data types) its not worth the effort\n",
    "--by default there is HIVA database\n",
    "--ATHENA - glue table or table that are stored in S3 data location is readble only if a folder contains only 1 file else incase your folder have multiple files/table then we've to add individual s3 suffix for each table\n",
    "--Glue Connections-create & store connections with redshift and other sources\n",
    "-ETL\n",
    "--visually create (glue will create script) else we can upload our script as well\n",
    "--Using Script as well we can create ETL Jobs to read and write from S3 to S3 or any other location be it redshift or anywhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 folder structure visible to us is logical in real its flat file structure and does not have folder management system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Serivices Used-\n",
    "IAM\n",
    "Glue\n",
    "S3\n",
    "Athena\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
