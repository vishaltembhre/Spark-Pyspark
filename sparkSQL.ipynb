{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQLApp\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Access SparkContext from SparkSession\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI is available at: http://LAPTOP-1DNSHCL1:4040\n"
     ]
    }
   ],
   "source": [
    "spark_ui_url = sc.uiWebUrl\n",
    "print(f\"Spark UI is available at: {spark_ui_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category| Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...|930995|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...|821630|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H05|Interest, dividen...|Financial perform...| 84354|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H07|Non-operating income|Financial perform...| 25010|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H08|   Total expenditure|Financial perform...|832964|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H09|Interest and dona...|Financial perform...| 55267|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H10|      Indirect taxes|Financial perform...|  7426|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H11|        Depreciation|Financial perform...| 30814|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H12|Salaries and wage...|Financial perform...|147663|  ANZSIC06 division...|\n",
      "|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H13|Redundancy and se...|Financial perform...|   269|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Read the CSV file\n",
    "    csv = spark.read.csv(\"C:/Users/Vishal/spark-pyspark/annual-enterprise-survey-2023-financial-year-provisional.csv\", header=True, inferSchema=True)\n",
    "\n",
    "    csv.createOrReplaceTempView(\"csv_table\")\n",
    "\n",
    "    result = spark.sql(\"SELECT * FROM csv_table LIMIT 10\")\n",
    "\n",
    "    # Show the result\n",
    "    result.show()\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark context\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
